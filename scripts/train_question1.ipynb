{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from torch import nn\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, load the data:\n",
    "def extract_df_from_jsons(json_path):\n",
    "    with open(json_path, 'r') as fl:\n",
    "        train_dict = json.load(fl)\n",
    "    \n",
    "    car_df = pd.DataFrame()\n",
    "    train_df = pd.DataFrame()\n",
    "    for train_id in train_dict.keys():\n",
    "        train = train_dict[train_id]\n",
    "        train['train_id'] = train_id\n",
    "        for car_id in train['cars']:\n",
    "            train['cars'][car_id]['car_id'] = car_id\n",
    "            train['cars'][car_id]['train_id'] = train_id\n",
    "        car_df = pd.concat([car_df, pd.DataFrame(train['cars']).T])\n",
    "        tmp = train.copy()\n",
    "        tmp.pop('cars')\n",
    "        train_df = pd.concat([train_df, pd.DataFrame(train, index=[train_id])])\n",
    "    train_df = train_df.drop('cars', axis=1)\n",
    "    return car_df, train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df, train_df = extract_df_from_jsons('../data/train_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these ammounts of data is the same as it was in reported in the book\n",
    "len(car_df), len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30000 [00:00<?, ?it/s]f:\\Anaconda\\envs\\torch-gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([36])) that is different to the input size (torch.Size([36, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 30000/30000 [00:13<00:00, 2143.20it/s]\n",
      "f:\\Anaconda\\envs\\torch-gpu\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss 0.0988 for num_wheels concept model.\n",
      "Final validation Loss 0.2070 for num_wheels concept model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:13<00:00, 2151.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss 0.9969 for length concept model.\n",
      "Final validation Loss 1.0026 for length concept model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:13<00:00, 2196.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss 5.7655 for shape concept model.\n",
      "Final validation Loss 4.4104 for shape concept model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:13<00:00, 2224.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss 0.5432 for num_load concept model.\n",
      "Final validation Loss 0.2066 for num_load concept model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:13<00:00, 2201.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss 3.5247 for shape_load concept model.\n",
      "Final validation Loss 4.6989 for shape_load concept model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:14<00:00, 2094.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss 0.8488 for next_crc concept model.\n",
      "Final validation Loss 1.1493 for next_crc concept model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:14<00:00, 2004.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss 0.3951 for next_hex concept model.\n",
      "Final validation Loss 0.0482 for next_hex concept model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:14<00:00, 2014.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss 0.9722 for next_rect concept model.\n",
      "Final validation Loss 0.6979 for next_rect concept model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:14<00:00, 2001.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss 0.9506 for next_tri concept model.\n",
      "Final validation Loss 1.2803 for next_tri concept model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# now defining the models\n",
    "\n",
    "# we will need 12 models\n",
    "# 11 concept models\n",
    "# and 1 meta-network\n",
    "\n",
    "# Since the concept models are basically all the same, I'll define one base model and make whichever changes are needed depending on the concept.\n",
    "\n",
    "class ConceptNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, bind_output=True):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.bind_output = bind_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        hlo = self.relu(x)\n",
    "        x = self.fc2(hlo)\n",
    "        if self.bind_output:\n",
    "            x = self.tanh(x)\n",
    "        return x, hlo\n",
    "\n",
    "class MetaNetwork(nn.Module):\n",
    "    def __init__(self, hidden_size_concepts, num_concepts, hidden_size, list_of_concept_models):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(hidden_size_concepts * num_concepts, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # self.concept_models = list_of_concept_models\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.tanh(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the networks\n",
    "num_cars = ConceptNetwork(2, 20, 1, False)\n",
    "num_loads = ConceptNetwork(2, 20, 1, False)\n",
    "num_wheels = ConceptNetwork(3, 20, 1, False)\n",
    "length = ConceptNetwork(3, 20, 1)\n",
    "shape = ConceptNetwork(3, 20, 1, False)\n",
    "num_car_loads = ConceptNetwork(3, 20, 1, False)\n",
    "load_shape = ConceptNetwork(3, 20, 1, False)\n",
    "next_crc = ConceptNetwork(3, 20, 1)\n",
    "next_hex = ConceptNetwork(3, 20, 1)\n",
    "next_rec = ConceptNetwork(3, 20, 1)\n",
    "next_tri = ConceptNetwork(3, 20, 1)\n",
    "\n",
    "# num_cars, num_loads\n",
    "list_of_concept_models = [num_wheels, length, shape, num_car_loads, load_shape, next_crc, next_hex, next_rec, next_tri, num_cars, num_loads]\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "list_of_optimizers = [optim.SGD(model.parameters(), lr = 0.01, momentum=0.01) for model in list_of_concept_models]\n",
    "\n",
    "# first I'll train each concept network for 30000 epochs (as in the book)\n",
    "\n",
    "#split the dataset: 36-4\n",
    "train_concept = car_df[car_df.train_id != '3']\n",
    "test_concept = car_df[car_df.train_id == '3']\n",
    "car_ids = train_concept.car_id.values.astype(np.float32)\n",
    "train_ids = train_concept.train_id.values.astype(np.float32)\n",
    "\n",
    "\n",
    "test_car_ids = test_concept.car_id.values.astype(np.float32)\n",
    "test_train_ids = test_concept.train_id.values.astype(np.float32)\n",
    "# Get the activation states of the hidden neurons in the other networks\n",
    "for model, optimizer, feat in zip(list_of_concept_models[:9], list_of_optimizers, train_concept.columns[:9]):\n",
    "    model.train()\n",
    "    train_features = train_concept[feat].values.astype(np.float32)\n",
    "    train_data = torch.tensor(list(zip(train_ids, car_ids, train_features)))\n",
    "    for t in tqdm(range(30000)):\n",
    "        \n",
    "        prediction, _ = model(train_data)\n",
    "        \n",
    "        loss = criterion(prediction, torch.tensor(train_features))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    test_features = test_concept[feat].values.astype(np.float32)\n",
    "    test_data = torch.tensor(list(zip(test_train_ids, test_car_ids, test_features)))\n",
    "    \n",
    "    model.eval()\n",
    "    prediction, _ = model(test_data)\n",
    "    val_loss = criterion(prediction, torch.tensor(test_features))\n",
    "    print(f\"Final training Loss {loss.item():.4f} for {feat} concept model.\")\n",
    "    print(f\"Final validation Loss {val_loss.item():.4f} for {feat} concept model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'train_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luido\\Documents\\GitHub\\RealtionNeuralSymbolicLearning\\scripts\\train_question1.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luido/Documents/GitHub/RealtionNeuralSymbolicLearning/scripts/train_question1.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m test_concept_num_car_features \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luido/Documents/GitHub/RealtionNeuralSymbolicLearning/scripts/train_question1.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test_concept_num_loads_features \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luido/Documents/GitHub/RealtionNeuralSymbolicLearning/scripts/train_question1.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m test_concept\u001b[39m.\u001b[39;49mtrain_id:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luido/Documents/GitHub/RealtionNeuralSymbolicLearning/scripts/train_question1.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     test_concept_num_car_features\u001b[39m.\u001b[39mappend(train_df\u001b[39m.\u001b[39mnum_car\u001b[39m.\u001b[39mloc[\u001b[39mid\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luido/Documents/GitHub/RealtionNeuralSymbolicLearning/scripts/train_question1.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     test_concept_num_loads_features\u001b[39m.\u001b[39mappend(train_df\u001b[39m.\u001b[39mdif_loads\u001b[39m.\u001b[39mloc[\u001b[39mid\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'train_id'"
     ]
    }
   ],
   "source": [
    "#now training the two other concept models that were left out num_cars and num_loads\n",
    "train_concept_num_car_features = []\n",
    "train_concept_num_loads_features = []\n",
    "for id in train_concept.train_id:\n",
    "    train_concept_num_car_features.append(train_df.num_car.loc[id])\n",
    "    train_concept_num_loads_features.append(train_df.dif_loads.loc[id])\n",
    "\n",
    "\n",
    "test_concept_num_car_features = []\n",
    "test_concept_num_loads_features = []\n",
    "for id in test_concept.train_id:\n",
    "    test_concept_num_car_features.append(train_df.num_car.loc[id])\n",
    "    test_concept_num_loads_features.append(train_df.dif_loads.loc[id])\n",
    "\n",
    "\n",
    "for model, optimizer, feat, test_concept in zip(list_of_concept_models[-2:], list_of_optimizers[-2:], [train_concept_num_car_features, train_concept_num_loads_features], [test_concept_num_car_features, test_concept_num_loads_features]):\n",
    "    model.train()\n",
    "    train_features = np.array(feat, dtype=np.float32)\n",
    "    train_data = torch.tensor(list(zip(train_ids, train_features)))\n",
    "    \n",
    "    for t in tqdm(range(30000)):    \n",
    "        prediction, _ = model(train_data)\n",
    "        \n",
    "        loss = criterion(prediction, torch.tensor(train_features))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 867.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#now train the meta network that infers wether the train is going east or not\n",
    "\n",
    "#first extracting the outputs from the hidden layers of each concept network\n",
    "hidden_layer_outputs = []\n",
    "for model, optimizer, feat in zip(list_of_concept_models[:9], list_of_optimizers, train_concept.columns[:9]):\n",
    "    model.eval()\n",
    "    train_features = train_concept[feat].values.astype(np.float32)\n",
    "    train_data = torch.tensor(list(zip(train_ids, car_ids, train_features)))\n",
    "    _, hlo = model(train_data)\n",
    "    hidden_layer_outputs.append(hlo)\n",
    "for model, optimizer, feat, test_concept in zip(list_of_concept_models[-2:], list_of_optimizers[-2:], [train_concept_num_car_features, train_concept_num_loads_features], [test_concept_num_car_features, test_concept_num_loads_features]):\n",
    "    model.eval()\n",
    "    train_features = np.array(feat, dtype=np.float32)\n",
    "    train_data = torch.tensor(list(zip(train_ids, train_features)))\n",
    "    _, hlo = model(train_data)\n",
    "    hidden_layer_outputs.append(hlo)\n",
    "\n",
    "\n",
    "direction_label = []\n",
    "for id in train_concept.train_id:\n",
    "    direction_label.append(train_df.east.loc[id])\n",
    "\n",
    "result = torch.cat([hlo.float() for hlo in hidden_layer_outputs], dim=1)\n",
    "\n",
    "metanetwork = MetaNetwork(20, 11, 3, list_of_concept_models)\n",
    "optimizer_meta = optim.SGD(metanetwork.parameters(), lr=0.3, momentum=0.4)\n",
    "for epoch in tqdm(range (10000)):\n",
    "    model.train()\n",
    "    predictions = metanetwork(result)\n",
    "    \n",
    "    loss = criterion(predictions, torch.tensor(direction_label, dtype=torch.float))\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dict = dict()\n",
    "\n",
    "for id, pred, gt in zip(train_concept.train_id, predictions.detach().numpy(), direction_label):\n",
    "    if id in prediction_dict.keys():\n",
    "        prediction_dict[id].append(pred)\n",
    "    else:\n",
    "        prediction_dict[id] = [pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in prediction_dict.keys():\n",
    "    prediction_dict[key] = np.mean(prediction_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0.71155846,\n",
       " '2': 0.6933832,\n",
       " '4': 0.755592,\n",
       " '5': 0.7793093,\n",
       " '6': 0.77550817,\n",
       " '7': 0.8135332,\n",
       " '8': 0.8658138,\n",
       " '9': 0.8813492,\n",
       " '10': 0.9201196}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16100314b3ba5fe3ed1a4dcc36124eb3da3396790081b2a994ef9064dc4ea70e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
